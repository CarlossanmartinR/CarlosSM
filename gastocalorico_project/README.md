# ðŸ”¥ PredicciÃ³n del Gasto CalÃ³rico con Machine Learning

Este proyecto tiene como objetivo predecir el gasto calÃ³rico de individuos utilizando tÃ©cnicas de regresiÃ³n aplicadas a un conjunto de datos proporcionado por una competencia de Kaggle. Se exploran mÃºltiples modelos y tÃ©cnicas de preprocesamiento para lograr el mejor rendimiento posible.

---

## ðŸ“ Estructura del proyecto

- `gasto_calorico.ipynb`: Notebook principal con todo el pipeline implementado.
- `train.csv`: Datos de entrenamiento.
- `test.csv`: Datos de prueba para predicciÃ³n.
- `submission.csv`: Archivo generado con las predicciones para Kaggle.

---

## âš™ï¸ Proceso general

1. **Carga y anÃ¡lisis exploratorio**
   - No se encontraron valores nulos en los datos.
   - Se realizaron anÃ¡lisis grÃ¡ficos para entender las relaciones entre variables.

2. **Preprocesamiento**
   - Tratamiento de outliers utilizando **winsorizing por IQR**.
   - ConversiÃ³n de variables categÃ³ricas (por ejemplo, `Sex`) a formato numÃ©rico.
   - CreaciÃ³n de nuevas variables derivadas como **IMC (Ãndice de Masa Corporal)**.

3. **SelecciÃ³n de caracterÃ­sticas**
   - Se evaluaron las correlaciones entre variables y se aplicÃ³ ingenierÃ­a de caracterÃ­sticas.
   - Se eliminaron algunas columnas como `Height` y `Weight` tras crear la columna `IMC`.

4. **Entrenamiento y evaluaciÃ³n de modelos**
   Se entrenaron y compararon los siguientes modelos usando validaciÃ³n cruzada:

   | Modelo                   | RMSE   | MAE   | RÂ²     |
   |--------------------------|--------|-------|--------|
   | Linear Regression        | 11.12  | 8.10  | 0.9681 |
   | Random Forest            | 4.46   | 2.81  | 0.9949 |
   | Lasso Regression (scaled)| 11.13  | 8.08  | 0.9681 |
   | Gradient Boosting        | 5.10   | 3.44  | 0.9933 |
   | CatBoost Regressor       | 3.97   | 2.47  | 0.9959 |
   | **Stacking Regressor**   | 3.97   | 2.46  | 0.9959 |

   > âœ… El mejor desempeÃ±o fue obtenido por el **Stacking Regressor**, con un excelente RÂ² y bajo error.

5. **Modelo final y predicciÃ³n**
   - Se entrenÃ³ el modelo final (Stacking Regressor) con todo el `df_train`.
   - Se aplicaron predicciones sobre `df_test`.
   - Se forzaron los valores negativos a cero debido a la mÃ©trica utilizada por Kaggle (MSLE).

---

## ðŸ“ˆ Modelo utilizado para `submission`

```python
final_model = StackingRegressor(...)
final_model.fit(X, y)
predictions = np.maximum(final_model.predict(X_test), 0)
